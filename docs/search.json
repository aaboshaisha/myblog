[
  {
    "objectID": "posts/lesson_9/index.html",
    "href": "posts/lesson_9/index.html",
    "title": "Stable Diffusion Core Ideas",
    "section": "",
    "text": "Below are some notes I took following Jeremy Howard’s wonderful lecture on Stable Diffusion Lesson 9: Deep Learning Foundations to Stable Diffusion, 2022. The lecture contains much more, but I summarized what I thought to be the core ideas / bare minimum for understanding.\nAll the included images are screenshots from the lecture (Thanks to lesson notes by rekil156. Check it for more detailed notes).\n\nThe thought process:\nSuppose we want to build a model that takes as input a random image and outputs a handwritten digit, how can we do it?\nWe know we can build models to recognize handwritten digits (input is an image of a handwritten digit and output is what the digit is eg 3 or 7). Perhaps then we can build a model (\\(f\\)) that tries to recognize the probability an image is a handwritten digit.\n\nWe can use this model to generate images of handwritten digits starting from random images. How?\nLet’s say we start with 28 x 28 pixel image - of some random pixels - as input to the model above eg X3. The model spits out the probability that X3 is a handwritten digit eg \\(P(X_3) = 0.02\\). What if we ask the model to adjust not its weights, but the pixels of the image \\(X3\\) itself, such that the \\(P(X3)\\) is handwritten digit goes up? If we do this enough times, we eventually end up with an image of a handwritten digit.\nHow can the model (\\(f\\)) know by how much it needs to change each pixel in X in order to make it a handwritten digit? Well, computing how much change is the gradient (here showing partial derivative): \\(\\frac{\\partial P(x3)}{\\partial x3}\\)\nSo, we want to train a function (nn) that gives us this gradient.\nHow do we train it?\nThis function tells us how close a “noisy” image or just “noise” is close to bring a handwritten digit. So, the model need to be able to quantify noise. It needs to know be able to go from img + noise -to-&gt; img.\n\neach input is pixels of a handwritten digit + noise from normal distribution\nAs humans we have a feeling for how much each of the images above is close to being a real handwritten digit. For a computer model (function) to do that, it’s hard to quantify this “feel” to it. The trick around this is if we make try to predict how much noise we added. The amount of noise tells us then how much of a digit it is (the more noise, the less like a digit).\n\nSo, we can generate this data.\n\nAnd train our model to predict noise (\\(n\\))\nOur model (nn) will have:\n\nInputs -noisy digits\nOutputs - noise\nloss function - MSE, between the predicted output(noise) and the actual noise\n\nAnd now we know that to turn this  to that  we need to remove this \nAnd this gives us the ability to calculate the gradient of each pixel in top image to make it look like 2nd img. The NN used to do this is a UNet\n\n\nThe problem of large image sizes:\nThe computation of the gradient for each image is quite computationally intesive. It’s a lot of compute for the \\(28 x 28\\) pixel images of handwritten digits (think one partial derivative for each pixel of a \\(28 x 28 pixel image = 784\\) done multiple times). And, we don’t want to do this only for handwritten digits in black and white. We want to do this for high quality artistic images like the \\(512 x 512 x 3\\) channel RGB images we have = \\(786,432\\) pixels.\nSolution: train on compressed images.\nCompression allows the small size while keeping the essential information in an image to retrieve it.\nHow can we compress images like this effeiciently?\nIdea: We pass images through successive convolutional layers with stride 2 (each time doubling the number of channels). At the end we add a few resnet like blocks to squish down the number of channels from 24 to 4.\n\nSo starting with \\(512x512x3\\) image, we get size of \\(64x64x4\\), we have compressed it by a factor of 48 (from \\(786432 to 16384\\) pixels).\nCompression is useful only if we can decompress (get the original image back). We can think of building the reverse architecture to do this (an inverse convolution that does the opposite).\n\nHow can we get this compression algorithm?\nThink of building this as one NN whose only function is to output the same image u gave as input.\nWhy is a model that does gives same output as input useful?\nCoz we can split it in half: the part that does the compression (encoder) and the one that decompresses (decoder).\nAnd now, if u have the decoder and the 16384 pixel image, u can get back the full 786432 pixel image.\nThese smaller compressed images are called “Latents”. We can pass them to our UNet above such that: - input: latents + noise - output : noise\nWe can subtract the output (noise) from the input (latents + noise) and get latents which we can decompress using the decoder.\nNB: ⁃ This whole encoder / decoder thing is called Autoencoder or VAE (Variational Autoencoder) ⁃ This VAE is optional. We can train on the full sized images if we’re Google and have tons of TPUs everywhere.\n\n\nWhere is my Text\nSuppose we want our handwritten digit generation model to generate a specific digit and not just anyone eg it can accept text and we tell it to generate “3” or “7” and so on. How can we do this?\nDuring training, we can pass it as input not just the img+noise but also a one-hot-encoded version of the number 3\n\nThis information (that the input image is a 3) is now avaiable for the model to make use of. It can now predict not just the noise but also that the original image is a 3 (we’re passing two things into this model, the image pixels and what digit it is in one hot encoded vector form).\nAfter training if we feed in “3”(one hot encoded) and the noise (img), it is going to say the noise is everything that doesn’t represent the number three. So this is called guidance. We can use that guidance to guide the model as to what image we want it to create.\nBut, we can’t do one-hot-encoded for everything. That would mean we need a one-hot-encoded representation of every sentence possible (infinite) eg “astronaut riding a horse”. What can we do instead?\nFor each image on the internet (where we collect data), there are usually alt tags (they will have some description of the image).\n\nWe can create two NNs / functions / models, one for the image and the other for the text. Each function spits out some random numbers (we will call them features). We then want the numbers / features for each model to be as close as possible to the numbers / features for its text and not at all like the features for other imgs & their txts. We make numbers similar via dot product\n\nWe can now think of our imgs and txt in a table. Each cell is the dot product score of img features x txt features. We want max at diagonals and small values elsewhere.\n\nThis is what we know as embeddings.\nOur loss function for this model can be defined as adding all the diagonal elements and subtracting from it the off-diagonal elements.\n\nWe can feed our text encoder with “a graceful swan”, “some beautiful swan”, “such a lovely swan” and these should all give very similar embeddings because these would all represent very similar images of swans. We’ve successfully created two models that put text and images into the same space, a multimodal(using more than one mode-images and text) model. Now, when we go back to our UNet model, we pass it these text features (which we know correspond to image features).\nThis pair of models are called : CLIP,Contrastive Language-Image Pre-training. The loss we are using is called contrastive loss.\nSo, in summary, we have:\n\nA Unet that can denoise latents into unnoisy latents\nThe decoder of VAE that can take latents and create an image\nThe CLIP text encoder which can guide the Unet with captions\n\n\nJargon:\nThe gradients that we calculate in UNet are called the score function.\nCreating noise:\nWe pick a t at random and use the correspinding sigma as noise (or beta in some papers). This is called time step."
  },
  {
    "objectID": "posts/second-post/index.html",
    "href": "posts/second-post/index.html",
    "title": "How to get blog up and running using quarto and github pages",
    "section": "",
    "text": "Anything below in italics is copied from quarto documentation(https://quarto.org/docs/publishing/github-pages.html)\n\nCreate a github repo “myblog”\nClone it to local drive git clone git@github.com:username/myblog.git\nIn the terminal, in the directory containing the cloned repo,create a new quarto blog project using: quarto create-project myblog --type website:blog\n“Simplest way to publish using GitHub Pages is to render to the docs directory and then check that directory into your repository”. We change the quarto project configurtion to use “docs” folder as the output directory by modifying the .quarto.yml file using:\n\n\nproject:\ntype: website\noutput-dir: docs\n\n\n“Add a .nojekyll file to the root of your repository that tells GitHub Pages not to do additional processing of your published site using Jekyll (the GitHub default site generation tool):”\n\nOn a Mac this is: touch .nojekyll\n\nThen render the site quarto render\n\nadd and commit all files to github\n&gt;&gt; git add .\n&gt;&gt; git commit -m “Your message”\n&gt;&gt; git push\n\n“Finally, configure your GitHub repository to publish from the docs directory of your main branch:”\n\n Img src: https://quarto.org/docs/publishing/github-pages.html\nNow, the website can be accessed at:\n\nusername.github.io/reponame/\n\nwhere username is ur github username and reponame in this example is myblog\nNote-1: Add a new post to your blog by creating a sub-directory within posts, and adding an index.qmd file to the directory. That qmd file is the new blog post and when you render that, the blog home page will automatically update to include the newest post at the top of the listing.\nNote-2: Once u add new post, run quarto render in the terminal, then add, commit and push to github to apply the changes to your blog online."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "On Brains and Machines",
    "section": "",
    "text": "EEG primer:\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n  \n\n\n\n\nStable Diffusion Core Ideas\n\n\n\n\n\n\n\nnotes\n\n\n\n\n\n\n\n\n\n\n\nMay 8, 2023\n\n\nAmr Aboshaisha\n\n\n\n\n\n\n  \n\n\n\n\nHow to get blog up and running using quarto and github pages\n\n\n\n\n\n\n\ncode\n\n\nhow-to\n\n\n\n\n\n\n\n\n\n\n\nMay 6, 2023\n\n\nAmr Aboshaisha\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "A personal notebook for some things I find interesting."
  },
  {
    "objectID": "posts/eeg_primer/index.html",
    "href": "posts/eeg_primer/index.html",
    "title": "EEG primer:",
    "section": "",
    "text": "EEG primer:\nBelow is a primer on EEG that heavily reies on the following paper (Electroencephalography: basic biophysical and technological aspects important for clinical applications.\n\nOverview\nThe electroencephalogram (EEG) is a non-invasive method to record electrical activity of the brain. It captures the sum of synchronized postsynaptic potentials (PSPs) of neurons such as excitatory (EPSPs) and inhibitory (IPSPs) postsynaptic potentials which occur when neurons communicate with each other.\nThe reason EEG signals appear in the form of waves is due to the nature of these neuronal communications and the way EEG captures and represents this activity. Here’s a more detailed breakdown:\n\nSynchronization of Neuronal Activity: EEG waves reflect the synchronized activity of neurons. When a large number of neurons receive excitatory inputs and become depolarized around the same time (EPSPs), or receive inhibitory inputs and become hyperpolarized (IPSPs), their combined activity produces detectable electrical fields. For an EEG signal to be detected on the scalp, the activity of many neurons must be synchronized in time and space. This synchronization leads to the rhythmic patterns observed in EEG recordings.\nSuperposition of PSPs: EEG waves result from the combined effect of many small excitatory (EPSPs) and inhibitory (IPSPs) postsynaptic potentials occurring in numerous neurons simultaneously, within a closely aligned timeframe. This phenomenon, known as superposition, involves the linear addition of individual neurons’ electrical potentials, producing a larger, detectable signal. For instance, simultaneous potentials of +2 mV and +3 mV from two neurons would collectively result in a +5 mV potential. As this synchronized activity involves thousands to millions of neurons, the EEG is able to capture a clear and strong signal representing this cumulative activity. The synchronization within specific time windows, detectable due to EEG’s high temporal resolution, leads to the emergence of distinct frequency bands (delta, theta, alpha, beta, gamma) that correlate with various brain states and cognitive processes.\nTypes of Waves Correspond to Brain Activity States: The brain operates in different states (e.g., wakefulness, different stages of sleep), and each state is characterized by different patterns of neuronal activity. For example, alpha waves are prominent when a person is awake but relaxed with closed eyes, while delta waves are seen during deep sleep. The type of wave observed reflects the predominant state of neuronal synchronization in various parts of the brain.\nPropagation of Electrical Fields: The electrical fields generated by neuronal activity propagate through the brain and surrounding tissues, including the skull and scalp, where they can be detected by EEG electrodes. The propagation of these fields can smooth out the signals, contributing to the wave-like appearance.\nFiltering and Amplification: EEG signals are often filtered and amplified to isolate specific frequency bands (e.g., alpha, beta, delta, theta, gamma) and enhance the signal-to-noise ratio. This processing can further accentuate the wave-like patterns of the EEG signals.\n\nThe specific frequency bands in EEG signals (alpha, beta, delta, theta, gamma) are defined based on the range of frequencies observed in the brain’s electrical activity and are associated with different states of brain function and consciousness. The origin of these bands comes from early EEG research, where patterns were observed that correlated with different physiological and psychological states. Here’s a brief overview of each band and its significance:\n\nDelta (δ) Waves (0.5–4 Hz): The slowest EEG waves, typically found in deep sleep and in infants. They are also observed during brain injuries, deep meditation, and in certain types of brain disorders. They indicate the lowest level of cognitive processing.\nTheta (θ) Waves (4–8 Hz): Associated with light sleep, relaxation, and drowsiness. They are also present during some meditative states and can be seen in deep emotional experiences. In children, theta waves are more prominent even during wakeful states. They are involved in memory, emotion, and some aspects of learning.\nAlpha (α) Waves (8–12 Hz): Typically observed in wakeful states when a person is at rest with eyes closed, reflecting a state of relaxation and calmness. They diminish when a person opens their eyes or becomes mentally engaged or alert. Alpha waves are considered a marker of the brain’s idle state or resting state network.\nBeta (β) Waves (12–30 Hz): Associated with active, alert consciousness and cognitive engagement. They are present during focused mental activities, problem-solving, judgment, decision making, and when a person is anxious or has their eyes open and is engaging with their environment.\nGamma (γ) Waves (30–100 Hz and above): Associated with higher mental activity, including perception, problem-solving, fear, and consciousness. They are thought to be involved in the formation of ideas, memory processing, and learning. Gamma waves have been linked to the integration of information across different parts of the brain.\n\nThis division allows researchers and clinicians to study and interpret the complex signals of the brain more effectively. For example, changes in the prevalence or power of these bands can indicate various neurological conditions, states of consciousness, or cognitive processes.\nRelation to Anatomy: The production of EEG wave types (alpha, beta, gamma, delta, theta) is influenced by both the state of brain activity and the anatomical regions of the brain, although there isn’t a strict one-to-one correspondence between each wave type and specific brain regions. Rather, different wave types can be more prominent or easily detected in certain areas under specific conditions. Here’s an overview of how each wave type relates to brain anatomy and function:\n\nDelta Waves: Predominantly observed in the frontal and temporal regions of the brain during deep sleep, delta waves can also appear in other brain areas during certain types of brain injuries or disorders. Their widespread distribution is associated with the deepest stages of sleep and general cortical inhibition.\nTheta Waves: These waves are commonly associated with the hippocampal and other limbic areas, crucial for memory formation and navigation. Theta rhythms are also seen in various cortical areas and are involved in tasks that require memory, navigation, and emotion, reflecting their role in cognitive and emotional processing.\nAlpha Waves: Alpha activity is most prominently observed in the posterior regions of the brain, particularly the occipital lobe when a person is awake but in a relaxed, eyes-closed state. However, alpha waves can also be modulated by attention and appear in frontal and central regions, indicating a broader role in integrating sensory information and cognitive processes.\nBeta Waves: Beta waves are distributed widely across the brain and are associated with active, logical thought, and alertness. They are prominent in the frontal lobes where higher cognitive processes occur and can also be detected in motor areas, reflecting their involvement in conscious movement and attention.\nGamma Waves: Gamma activity is thought to be involved in higher mental activity, including perception, problem-solving, and consciousness, and has been detected in various brain regions. It is often associated with the process of binding different sensory and cognitive experiences into a coherent whole. Gamma waves are observed in many areas of the brain, including the visual cortex, where they are involved in processing visual stimuli, and in frontal brain areas involved in attention and working memory.\n\nHere’s a structured way to remember them, starting from the slowest to the fastest frequencies:\n\nDelta Waves (0.5–4 Hz)\n\nMnemonic: “Deep sleep Delta”\nPsychological Association: Deep sleep, unconsciousness\nAnatomical Association: Frontal and temporal regions during sleep, widespread during deep sleep or brain disorders\nMemory Aid: Think of “Delta” as “Deep” in “Deep sleep”.\n\n\n\nTheta Waves (4–8 Hz)\n\nMnemonic: “Thoughtful Theta”\nPsychological Association: Light sleep, drowsiness, creative and emotional insights\nAnatomical Association: Hippocampus and limbic areas, associated with memory and navigation\nMemory Aid: “Theta” for “Thinking” in a dreamy, creative way.\n\n\n\nAlpha Waves (8–12 Hz)\n\nMnemonic: “Awake but Relaxed Alpha”\nPsychological Association: Relaxed, calm, meditation, eyes closed\nAnatomical Association: Primarily occipital lobe but also seen in posterior regions; related to wakeful relaxation\nMemory Aid: “Alpha” as in “Alert but at rest”.\n\n\n\nBeta Waves (12–30 Hz)\n\nMnemonic: “Busy Beta”\nPsychological Association: Active thinking, focus, high alertness, anxiety\nAnatomical Association: Frontal and motor cortex, widespread during active thought and concentration\nMemory Aid: “Beta” for “Being actively engaged”.\n\n\n\nGamma Waves (30–100 Hz and above)\n\nMnemonic: “Great Gamma”\nPsychological Association: High-level information processing, learning, perception\nAnatomical Association: Various regions, involved in integrating sensory and cognitive functions\nMemory Aid: “Gamma” for “Greater” cognitive processes.\n\n\nGeneral Tip\nYou can use the sequence of the waves (Delta, Theta, Alpha, Beta, Gamma) to remember their order from slowest to fastest and associate them with going from deep sleep (Delta) to high cognitive processing (Gamma). It progresses much like human activity levels through the day, from deep sleep to peak activity.\n\n\n\nProvocative methods that increase the diagnostic yield - techniques used during EEG recordings to enhance the detection of abnormalities, particularly in patients with epilepsy:\n\nProvocative Maneuvers: These are specific actions or conditions applied during EEG recordings to trigger brain activity that might not be visible under normal conditions. The goal is to increase the chances of detecting any abnormalities.\nHyperventilation: Patients are asked to breathe deeply and rapidly for 3-5 minutes. This can be particularly revealing but is not suitable for everyone, especially those with certain medical conditions. Observing the EEG for a couple of minutes after hyperventilation is crucial as changes can occur during this post-hyperventilation phase.\nPhotic Stimulation: This involves exposing the patient to flashing lights to trigger brain activity. It’s especially useful for identifying photosensitivity, which can be linked to seizures. It should be performed in dim lighting and before hyperventilation to differentiate its effects from those of hyperventilation.\nSleep: Including sleep in the EEG recording can reveal abnormalities that only occur during sleep or are more pronounced during sleep states. In younger children, sleep during the EEG is often naturally occurring, while in others, it may be induced through various means like sleep deprivation or medication.\nSpecialized Provocative Maneuvers: In certain cases, specific actions related to the patient’s symptoms (e.g., reading for those with reading epilepsy) are included in the EEG recording to provoke the characteristic brain activity associated with their condition.\n\nThese methods are integral to standard EEG procedures, enhancing the diagnostic accuracy by revealing epileptic activity and other abnormalities that might not be evident under normal observation conditions.\n\n\nTypes of EEG recordings - essentials of conducting EEG (electroencephalography) recordings to ensure diagnostic accuracy, particularly in identifying transient abnormalities:\n\nStandard Routine Recording: A typical EEG session should last at least 20 minutes of clear, artifact-free recording. This duration is crucial to capture any transient, abnormal EEG patterns that might indicate neurological issues, such as epilepsy. Artifacts are unwanted signals that can interfere with the interpretation of the EEG, coming from muscle movements, eye blinks, or electrical interference, so it’s important to minimize these.\nIncorporation of Provocative Maneuvers: Besides the basic recording, the session should include certain provocative maneuvers that can help elicit abnormalities. These could be specific actions or stimuli that provoke a response in the brain, helping to reveal conditions that might not be apparent under normal circumstances.\nVariability in Recording Conditions: The EEG should document the brain’s activity both when the patient’s eyes are open and when they are closed. This helps in assessing how the brain responds to different states of sensory input. For patients who are unable to voluntarily open and close their eyes, the technician might need to assist, ensuring that the recording accurately reflects these conditions.\nSpecial Considerations for Children: When recording EEGs from children, especially those who might not cooperate fully with instructions, creative strategies like the use of a cuddly toy can help in managing the child’s state and ensuring a successful recording session.\n\n\n\n\nA more detailed dive:\n\nThe electric source of the EEG signals - how EEG signals are generated and recorded:\nEEG signals are the result of electrical activities happening in the brain, specifically from the flow of ionic currents across the membranes of dendrites in the pyramidal neurons located in the middle layers (IV - V) of the brain’s cortex.\n\nHow Signals Are Generated: The signals start in the dendrites of neurons which receive signals from other neurons. When these signals are excitatory, they cause the dendrite to become slightly more positively charged by allowing positive ions (like sodium) to flow in. This creates a difference in charge, or a dipole, across the dendrite’s membrane.\nExtracellular Currents: The EEG doesn’t measure the activity inside the neuron directly because the cell membrane is an insulator. Instead, it records the movement of currents outside the neuron in the extracellular space. This movement creates what are known as local field potentials (LFPs).\nVolume-Conduction: The process by which these electrical signals travel through the brain tissue and skull to be recorded by electrodes on the scalp is termed “volume-conduction”. It’s kind of like how the sound from a speaker can fill a room and be heard from anywhere within that room.\nAction Potentials vs. Postsynaptic Potentials: While action potentials (brief, large changes in membrane potential that travel along the neuron) are essential for neuron-to-neuron communication, they don’t significantly contribute to the EEG signals. This is because they are too short-lived and occur in too few neurons at any given time to be detected outside of the skull. Instead, the EEG captures the sum of many excitatory (EPSPs) and inhibitory (IPSPs) postsynaptic potentials, which are longer-lasting and occur in many neurons simultaneously.\nSynchronization: For an EEG signal to be detectable on the scalp, a large number of neurons (around 10 cm² of cortex) need to be activated in a synchronized manner. This synchronization results in a measurable electrical field at the scalp.\nTopography: The position and orientation of the neurons that are active determine the pattern of electrical potentials seen on the scalp. This pattern, or topography, can be visualized with special maps that show the distribution of electrical activity across the scalp.\n\nIn essence, the EEG records the collective hum of electrical activity from the brain’s neurons, much like listening to the buzz of a crowd from a distance. The specific patterns and rhythms in this buzz can tell us a lot about what’s happening in the brain, from basic sensory processing to complex cognitive activities.\n\n\nEEG electrodes and recording arrays - the technology behind capturing EEG signals and the setup of EEG recordings:\n\nElectrodes: EEG electrodes are the crucial link between the patient’s brain activity and the EEG recording device. They pick up the electrical signals generated by the brain.\nPlacement: Electrodes are placed on the scalp at specific locations according to standardized guidelines (like the International 10-20 system). This system uses key anatomical landmarks on the skull to position the electrodes accurately, ensuring consistent recordings across different individuals and studies.\nElectrode Arrays and Reference Electrodes: The electrodes are arranged in arrays to cover different parts of the scalp. Reference electrodes are used as a baseline to compare and measure the brain’s electrical activity accurately. Different types of electrode arrangements (montages - see below) can be used depending on the goals of the EEG recording.\nImpedance and Signal Quality: Electrode impedance is a measure of resistance to the flow of electrical current. Proper impedance levels are crucial for minimizing noise and ensuring high-quality recordings. Too high or too low impedance can lead to poor signal quality or artifacts.\n\n\n\nEEG amplifiers - how the small electrical signals picked up by EEG electrodes from the brain are processed so that they can be analyzed:\n\nDifferential Measurement: Each electrode placed on the scalp (the “active” electrode) records the electrical activity from a particular area of the brain. An EEG channel then measures the difference in electrical potential (voltage) between two points: an “active” electrode (one of the scalp electrodes) and a “reference” electrode. This differential measurement helps in identifying the specific electrical activity coming from the brain, as opposed to electrical noise or activity from other sources.\nAmplification: The original signals recorded by the scalp electrodes (which are in the order of microvolts, μV) are too small to work with directly. The primary role of an EEG amplifier is to make them larger, or amplify them, so that they can be analyzed and interpreted.\n\nThink of each channel as a distinct line or stream of information coming from a specific spot on the head. When you have multiple channels, you’re collecting data from multiple spots simultaneously, allowing you to see what different parts of the brain are doing at any given time.\nThe number of channels recorded in an EEG can vary widely depending on the purpose of the recording, the complexity of the study, and the equipment being used. Common setups include:\n\nStandard Clinical EEG: Often uses 19 to 21 channels, based on the international 10-20 system for electrode placement. This system provides a good coverage of the entire scalp for routine clinical diagnostics and monitoring.\nResearch and Advanced Clinical Studies: May use 32, 64, 128, or even more channels for more detailed brain activity mapping. High-density EEGs, with 128 channels or more, are used for research purposes that require high spatial resolution to accurately localize brain activity.\nConversion to Digital Signals: After amplification, the analogue electrical signals are converted into digital signals. This conversion allows the EEG data to be stored, displayed on a computer screen, and analyzed using various computational methods. The conversion process involves measuring the voltage at very short intervals (time-frames) and converting these measurements into digital values (numbers) that represent the signal’s strength and quality over time.\nSampling Frequency: How often the voltage is measured per second is called sampling frequency. To accurately capture the EEG signal, the sampling frequency needs to be at least twice as high as the highest frequency in the EEG signal that researchers wish to observe. This is known as the Nyquist rate. For clinical EEG, a minimum standard sampling frequency is 128 samples per second, but higher frequencies can provide better resolution.\n\n\n\nFilters - how EEG recordings are refined to improve the quality of the data captured from the brain’s electrical activity:\n\nPurpose of Filters: Since the brain’s electrical signals are very weak, they can easily be contaminated by other electrical signals from muscles, electrical devices, or other sources. Filters are used in EEG recordings to remove or reduce unwanted signals or noise without affecting the important brain signals we want to study.\nTypes of Filters:\n\nLow-Pass Filters: These filters allow signals below a certain frequency to pass through while blocking higher frequency signals. This is useful for removing high-frequency noise, such as muscle activity, that might interfere with the EEG data.\nHigh-Pass Filters: These filters do the opposite, allowing signals above a certain frequency to pass and blocking lower frequency signals. This can help remove slow-moving signal artifacts caused by movement or breathing.\nBand-Pass Filters: A combination of low-pass and high-pass filters, allowing only signals within a certain frequency range to pass through. This is helpful for isolating the frequency range most relevant to the study.\nNotch Filters: These are designed to remove very specific frequencies from the EEG data, such as the electrical noise from power lines (usually 50 or 60 Hz, depending on the country).\n\nAliasing: when the sampling frequency (how often the EEG signal is recorded per second) is too low compared to the frequency of the brain signals, this is called aliasing. Aliasing can distort the recorded signal, making it appear as a lower frequency than it actually is. To prevent this, the sampling frequency must be at least twice the highest frequency in the EEG signal (known as the Nyquist rate).\n\nIt’s something like trying to take a picture of a fast-moving car with a slow camera. If the camera takes pictures too slowly, the car might look like it’s in a different position than it actually is, or in some cases, it might even appear to be moving backwards.\n\nAnti-Aliasing Filters: Before the EEG signal is converted from analog to digital (a necessary step for analysis), an anti-aliasing filter is applied to prevent distortion by removing high-frequency components that cannot be correctly sampled.\nDigital Filters: After the EEG signal has been digitized, digital filters can be applied to further clean up the signal. Unlike analog filters used before digitization, digital filters can be adjusted after the recording to optimize the analysis of the EEG data.\nPitfalls of Over-Filtration: Overusing filters can lead to the loss of important information in the EEG signal or the introduction of artifacts that could be mistaken for brain activity.\n\n\n\nDisplay: visualization of the EEG signals - how EEG data, after being collected and processed, is visually represented for analysis:\nTo visualize EEG data and understand what’s happening in the brain, you can follow these simple steps:\n\nSet Up the Display: First, the EEG data appears on a screen, laid out like an oscilloscope so that time moves from left to right and brain signal strength goes up and down. This view lets you see changes in brain activity as they happen.\nLearn About the Axes:\n\nThe up-and-down direction (vertical axis) shows the signal’s strength in microvolts. By convention (and a bit counterintuitive), lower values go up and higher values go down.\nThe left-to-right direction (horizontal axis) tracks time, showing how brain activity shifts. Typically, a certain length, like 30 mm, will stand for one second, but you can adjust this to zoom in or out on the data.\n\nTweak How Things Look:\n\nPaper Speed: This changes how much time you see on the screen. Speed it up to look more closely at a short moment, or slow it down to get a bigger picture over a longer time.\nGain: This adjusts how big or small the waves look, helping you focus on different parts of the EEG signal.\n\nChoose a Montage: A montage is a way of organizing the display to compare signals from various parts of the brain. Picking the right montage can help highlight the specific brain activities you’re interested in.\nZoom and Adjust for Better Analysis: With digital EEG, you can zoom in to take a closer look at certain events, like seizures, or zoom out to understand the brain’s activity pattern over time. This flexibility is key for a thorough analysis.\n\n\n\nMontages - how EEG signals can be arranged and analyzed to highlight different aspects of brain activity:\n\nWhat Are Montages?: Montages in EEG are specific arrangements of how the electrical signals from the brain, captured by electrodes on the scalp, are displayed and analyzed. They help in comparing signals from different parts of the brain to detect patterns, abnormalities, or specific activities.\nTypes of Montages Explained:\n\nReferential Montages: Compare the signal from each electrode to a common reference point (an electrode placed at a neutral location). It’s useful for pinpointing where brain activity is happening relative to this common point. However, the choice of reference electrode is crucial because it can influence how the activity is interpreted.\nBipolar Montages: Compare the signals from pairs of electrodes to each other. This method is good for seeing how electrical activity flows between two adjacent areas on the scalp, providing a sense of the activity’s direction or pathway across the brain.\nCommon Average Montage: The activity from all electrodes is averaged to create a baseline. The activity at each electrode is then compared to this average. This montage is beneficial for identifying areas of the brain that are more or less active compared to the overall brain activity average.\n\n\nThe selection of montage depends on the specific goals of the EEG analysis. Different montages can reveal different information about brain activity.\n\n\nEstimation of the source using EEG montages - how the positioning and direction of the brain’s electrical activity sources influence the waveforms observed in different EEG montage setups:\nThe way groups of neurons (Source) are oriented in the brain changes how we see their signals on an EEG:\n\nIf neurons fire together in a direction that’s straight up and down (perpendicular to the brain’s surface), they make a strong, focused negative signal on the EEG. Around this, there’s a weaker, more spread-out positive signal.\nWhen neurons fire in a direction that’s flat or parallel to the brain’s surface (tangential), they create two separate signals, one negative and one positive, on the EEG. In setups where the EEG compares signals between pairs of electrodes (bipolar montages), these positive and negative signals can show up at the ends of the electrode chains. This makes it tricky to pinpoint where the neurons are firing without looking at how the signals change from negative to positive.\nBipolar montages are good for finding the spot with the strongest negative signal because they compare the difference in signal strength between pairs of electrodes. The spot with the strongest activity shows a unique pattern, known as “negative phase-reversal,” which helps identify where the most intense brain activity is.\nAnother setup, the common average montage, gives a clearer view by highlighting the main spot of activity with a large negative signal and showing smaller positive signals around it. This makes it easier to see both the specific area of intense activity and its wider effects.\n\nEach way of setting up the EEG (montage) has its pros and cons. Bipolar montages might not catch the broader positive signals well because they focus on the small differences in signal strength between close-by electrodes. However, they excel at locating the most active brain area. It’s important for those analyzing the EEG to understand these details to read the signals correctly.\nNB (can be skipped): “the ends of the electrode chains” : An “electrode chain” is a sequence of electrodes connected or considered in series for the purpose of measurement. In bipolar montages, each pair of electrodes is used to measure the difference in electrical potential between them. So, “the ends of the electrode chains” means the first and last electrodes in a sequence or chain of electrodes that are being used to compare electrical signals across different parts of the scalp.\nIn this setup, the brain’s electrical signals are detected as differences in voltage between adjacent electrodes along the chain. Positive and negative signals appearing at the ends of these chains can indicate the directional flow of electrical activity, but pinpointing the exact source of activity requires analyzing the transitions between negative and positive signals across the sequence of electrodes. This arrangement helps in tracing the path of electrical activity across the scalp, but it can make it challenging to precisely locate the origin of the activity without considering the overall pattern of signals in the chain.\n\n\nEstimation of the source using voltage maps - how to use voltage maps for identifying the origins of electrical activity in the brain, as recorded by EEG:\nVoltage maps are digital EEG tools that show where brain activity starts by displaying negative and positive electrical potentials across the scalp with color codes—blue for negative and red for positive. The intensity of the color reflects the strength of the signal.\nThe source’s orientation, whether radial (outwards from the head’s center) or tangential (parallel to the skull), changes how activity appears on these maps. Radial sources produce a strong negative signal directly above them, encircled by weaker positive signals. Tangential sources generate two distinct poles, one negative and one positive, on the scalp.\nTo locate the start of brain activity: - For radial sources, search for areas showing large negative signals. - For tangential sources, identify the highest signal strength change by connecting the strongest negative and positive signals. The source lies beneath this point.\nAdditionally, the activity’s direction is indicated by the side facing the negative signals, pointing towards the brain area responsible for the activity.\n\n\nSummary:\n\nEEG stands as the most commonly used method for investigating functional issues in patients experiencing seizures and suspected epilepsy.\nNeurons residing in layers IV-V generate EEG signals through the summation of postsynaptic potentials along their apical dendrites.\nCurrents conducted through the brain volume to the scalp surface create a topography of positive and negative potentials, shaped by the position and orientation of the cortical generator.\nStandard (International Federation of Clinical Neurophysiology) EEG electrode array comprises 25 scalp electrodes.\nDigital EEG recordings use a common reference electrode, filtering analogue electrical signals, converting them to digital format, and re-montaging them.\nEEGs display like an oscilloscope, plotting voltage changes vertically against time horizontally, with negative polarity pointed upwards.\nVarious montages, such as bipolar and referential or common average and source, help in displaying signals from active electrodes by using another scalp electrode or a calculated value as a reference.\nTo estimate the cortical source visually, examining the distribution of negative and positive potentials using topographic (voltage) maps is highly effective.\nEmploying provocative maneuvers like hyperventilation, intermittent photic stimulation, and sleep can enhance the diagnostic yield of EEG recordings.\nSeveral clinical EEG recording types are available, including standard, sleep, short and long-term video-EEG recordings, and invasive (intracranial) recordings."
  }
]